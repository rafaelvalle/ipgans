In this paper we investigated numerical properties of samples produced 
with adversarial methods, specially Generative Adversarial Networks. We showed that GAN samples have universal signatures that are dependent on the choice of non-linearity on the last layer of the generator. In addition, we showed that adversarial examples produced with the FSGM have properties that can be used to identify an adversarial attack. Following, we showed that GAN samples smoothly approximate the dominating modes of the distribution and that this information can be used to identify the source of the data. Finally, we showed that samples generated with GANs do not provide guarantees on satisfaction of simple specifications. With this we hope to call attention to our community to the necessity of developing a theory of verifiable artificial intelligence.