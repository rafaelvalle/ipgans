Since the groundbreaking Generative Adversarial Networks
paper~\cite{goodfellow2014generative} in 2014, GAN related
publications use a grid of image samples to accompany theoretical and empirical
results. GAN research focuses is expanding to other domains including language 
models~\cite{gulrajani2017improved} and music~\cite{yang2017midigan}, requiring
new methods of sample inspection.

Unlike variational auto encoders and other
models~\cite{goodfellow2014generative}, most of the evaluation of the output
of Generators trained with the GAN framework is qualitative: authors normally 
list higher sample quality as one of the advantages of their method over other
methods.  Interestingly, little is mentioned about the numerical properties of
GAN samples and how these properties compare to real samples.

In the context of verifiable Artificial Intelligence\cite{seshia2016vai}, 
it is hard to systematically verify the Generator because verification depends 
on the existence of perceptually meaningful features. For example, consider the 
generation of images of mamals: although it is possible to compare color histograms 
of fake\footnote{Generated samples} and real samples, we do not yet have robust 
algorithms able to verify if an image follows specifications derived from anatomy. 

This paper is related to this effort and focuses on understanding the numerical 
properties of GAN samples. We investigate how the Generator approximate modes 
in the real distribution and verify if the generated samples violate specifications 
derived from the real distribution. We offer the following contributions in this paper: 
\begin{itemize}
\item We show that GAN samples have universal signatures.
\item We show how GAN samples approximate modes of the real distribution.
\item We show significant differences between the marginal distribution of features. 
\item We show GAN samples that violate specifications in the real data.
\end{itemize}
