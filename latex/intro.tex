Since the groundbreaking Generative Adversarial Networks
paper~\cite{goodfellow2014generative} in 2014, most GAN related
publications use a grid of image samples to accompany theoretical and empirical
results. Given this context, the expansion of GAN research to other domains including language 
models~\cite{gulrajani2017improved} and music~\cite{yang2017midigan} display the
need of sample inspection.

Unlike Variational Autoencoders (VAEs) and other
models~\cite{goodfellow2014generative}, most of the evaluation of the output
of Generators trained with the GAN framework is qualitative: authors normally 
list higher sample quality as one of the advantages of their method over other
methods.  Interestingly, little is mentioned about the numerical properties of
GAN samples and how these properties compare to real samples.

In the context of Verified Artificial Intelligence\cite{seshia2016vai}, 
it is hard to systematically verify the Generator and the samples it produces
because verification might depend on the existence of perceptually meaningful features. For example, consider the 
generation of images of humans: although it is possible to compare color histograms 
of real and fake\footnote{Generated samples} samples, we do not yet have robust 
algorithms able to verify if an image follows specifications derived from anatomy. 

This paper is related to this systematic sample verification and focuses on
understanding the numerical properties of GAN samples. We investigate how the
Generator approximates modes 
in the real distribution and verify if the generated samples violate specifications 
derived from the real distribution. We offer the following contributions in this paper: 
\begin{itemize}
\item We show that GAN samples have universal signatures.
\item We show how GAN samples approximate modes of the real distribution.
\item We show significant differences between the marginal distribution of features. 
\item We show GAN samples that violate specifications in the real data.
\end{itemize}
